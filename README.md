# MachineLearning

<h1>This catalog of NLP Primers focuses on important topics such as</h1>
<table>
  <tr>
    <th>No</th>
    <th>Notes</th>
    <th>URLS</th>
  </tr>
  <tr>
    <td>1</td>
    <td>Word Vectors/Embeddings</td>
    <td>http://embeddings.aman.ai</td>
  </tr>
  <tr>
    <td>2</td>
    <td>AWS Architecture Blog</td>
    <td>https://lnkd.in/eEchKJif</td>
  </tr>
   <tr>
    <td>3</td>
    <td>System design newsletter</td>
    <td>https://github.com/systemdesign42/system-design?tab=readme-ov-file#p-companies</td>
  </tr>
  <tr>
    <td>1</td>
    <td>Word Vectors/Embeddings</td>
    <td>http://embeddings.aman.ai</td>
  </tr>
   <tr>
    <td>2</td>
    <td>NLP Tasks</td>
    <td>http://nlp-tasks.aman.ai</td>
  </tr>
   <tr>
    <td>3</td>
    <td>Preprocessing</td>
    <td>http://tokenizer.aman.ai</td>
  </tr>
   <tr>
    <td>4</td>
    <td>Tokenization</td>
    <td>http://tokenizer.aman.ai</td>
  </tr>
   <tr>
    <td>5</td>
    <td>Attention</td>
    <td>http://attention.aman.ai</td>
  </tr>
   <tr>
    <td>6</td>
    <td>Transformers</td>
    <td>http://transformer.aman.ai</td>
  </tr>
   <tr>
    <td>7</td>
    <td>Overview of LLMs</td>
    <td>http://llm.aman.ai</td>
  </tr>  
   <tr>
    <td>8</td>
    <td>Overview of VLMs</td>
    <td>http://vlm.aman.ai</td>
  </tr>   
   <tr>
    <td>9</td>
    <td>Parameter Efficient Fine-Tuning</td>
    <td>http://peft.aman.ai</td>
  </tr>  
   <tr>
    <td>10</td>
    <td>LLM Alignment</td>
    <td>http://alignment.aman.ai</td>
  </tr> 
   <tr>
    <td>11</td>
    <td>Retrieval Augmented Generation (RAG)</td>
    <td>http://rag.aman.ai</td>
  </tr>  
   <tr>
    <td>12</td>
    <td>Context Length Extension</td>
    <td>http://llm-context.aman.ai</td>
  </tr>    
  </tr>  
   <tr>
    <td>13</td>
    <td>Document Intelligence</td>
    <td>http://token-smple.aman.ai</td>
  </tr>   
  </tr>  
   <tr>
    <td>14</td>
    <td>Token Sampling Methods</td>
    <td>http://llm-context.aman.ai</td>
  </tr>   
  </tr>  
   <tr>
    <td>15</td>
    <td>Autoregressive vs. Autoencoder Models</td>
    <td>http://enc-dec.aman.ai</td>
  </tr>  
   <tr>
    <td>16</td>
    <td>Evaluation Metrics</td>
    <td>http://metrics.aman.ai</td>
  </tr>
   <tr>
    <td>17</td>
    <td>Textual Entailment</td>
    <td>http://entailment.aman.ai</td>
  </tr>
   <tr>
    <td>18</td>
    <td>BERT</td>
    <td>http://bert.aman.ai</td>
  </tr>
   <tr>
    <td>19</td>
    <td>GPT</td>
    <td>http://gpt.aman.ai</td>
  </tr>
   <tr>
    <td>20</td>
    <td>Llama</td>
    <td>http://llama.aman.ai</td>
  </tr>  
   <tr>
    <td>21</td>
    <td>Gemini</td>
    <td>http://gemini.aman.ai</td>
  </tr>    
   <tr>
    <td>22</td>
    <td>Toolformer</td>
    <td>http://toolformer.aman.ai</td>
  </tr>  
   <tr>
    <td>23</td>
    <td>Knowledge Graphs</td>
    <td>http://kg.aman.ai</td>
  </tr>  
   <tr>
    <td>24</td>
    <td>Hallucination Mitigation</td>
    <td>http://hallu-mitgn.aman.ai</td>
  </tr>  
   <tr>
    <td>25</td>
    <td>Named Entity Recognition</td>
    <td>http://ner.aman.ai</td>
  </tr>    
   <tr>
    <td>26</td>
    <td>Machine Translation</td>
    <td>http://translatn.aman.ai</td>
  </tr>  
   <tr>
    <td>27</td>
    <td>AI Generated Text Detection Techniques</td>
    <td>http://ai-detect.aman.ai</td>
  </tr>  
   <tr>
    <td>28</td>
    <td>Document Intelligence</td>
    <td>http://doc-intel.aman.ai</td>
  </tr> 
   <tr>
    <td>29</td>
    <td>Top Papers in NLP Research</td>
    <td>http://nlp-papers.aman.ai</td>
  </tr>
   <tr>
    <td>30</td>
    <td>AMAN Blog</td>
    <td>https://aman.ai/primers/ai/</td>
  </tr>    
</table>



<h1>BOOKS</h1>
<p>https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/</p>


<h1>GITHUB Links</h1>
<p>https://github.com/khuyentran1401/Data-science</p>

<p>https://github.com/ashishpatel26/ResourceBank_CV_NLP_MLOPS_2022</p>

<p>https://github.com/TheAlgorithms/Jupyter</p>

<p>https://github.com/trekhleb/homemade-machine-learning</p>

<h1>Research Papers</h1>
<p>https://applyingml.com/papers/</p>
<p>Stanford :</p>

<p>https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks</p>

<p>https://stanford.edu/~shervine/teaching/cs-221/</p>

<p>https://www.datacamp.com/cheat-sheet/machine-learning-cheat-sheet</p>

<p>NLP:</p>
<p>https://index.quantumstat.com/</p>


<h1>Blog Post</h1>
<p>https://www.amazon.science/blog/top-10-blog-posts-of-2022</p>

<h1>Websites</h1>
https://huyenchip.com/machine-learning-systems-design/design-a-machine-learning-system.html#model-selection-eRQEIDR


<h1>ğ“ğ¨ğ© ğŸğŸ ğ›ğğ¬ğ­ ğ‚ğ¨ğ®ğ«ğ¬ğğ¬ ğ‹ğ¢ğ¬ğ­ :</h1>
<P>ğŸ”¸Harvard CS 109A Data Science - https://lnkd.in/dcKQ9fuQ </P>

<P>ğŸ”¸Stanford CS229: Machine Learning - https://lnkd.in/dtDUHgbA </P>

<P>ğŸ”¸ Columbia COMS W4995: Applied Machine Learning - https://lnkd.in/d6wT4Y8u </P>

<P>ğŸ”¸ edX ColumbiaX: Machine Learning - https://lnkd.in/d9fWNiZP </P>

<P>ğŸ”¸ Berkeley CS294: Fairness in Machine Learning - https://lnkd.in/dRNaEUY2 </P>

<P>ğŸ”¸ Google: Machine Learning Crash Course - https://lnkd.in/dYcR_ne2 </P>

<P>ğŸ”¸ Google: AI Education - https://lnkd.in/dAPMhDaS </P>

<P>ğŸ”¸ Google: Applied Machine Learning Intensive - https://lnkd.in/d39vqqSA </P>

<P>ğŸ”¸ Cornell Tech CS5785: Applied Machine Learning - https://lnkd.in/dPv433vh </P>

<P>ğŸ”¸ Probabilistic Machine Learning (Summer 2020) - https://lnkd.in/d5y-susP </P>

<P>ğŸ”¸ AutoML - Automated Machine Learning - https://lnkd.in/dHgep85n </P>



<h1>Best Resource for Recommendation Systems</h1>

<p>If you are working on Recommendation Systems then there are 3 great places to learn from. There are various implementation methods along with several example notebooks.</p>

<p>1. https://lnkd.in/e6QzR7AA (Microsoft)</p>

<p>2. https://lnkd.in/eTHaXSXn (Google)</p>

<p>3. https://lnkd.in/edzU4xMy</p>

<p>example notebooks:</p>
<p>1. https://lnkd.in/erKHP3EE </p>

<p>2. https://lnkd.in/etQaDhPN </p>

<p>3. https://lnkd.in/exSuQBYg</p>




